{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOgAra7nqIJBtnMVoie/H77"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Utilizziamo la PCA, sulla base dei risultati ottenuti dall'EFA, per effettuare un ridimensionamento del dataset in modo che ogni riga sia della stessa dimensione (600 elementi)"],"metadata":{"id":"DeSw0CUmSskq"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wi_W-J6QDvCh","executionInfo":{"status":"ok","timestamp":1654955934526,"user_tz":-120,"elapsed":31926,"user":{"displayName":"MARCO COSTANTE","userId":"15932919196425756725"}},"outputId":"0b55082a-2193-48fd-b9a2-0b330a59494a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJZgwEuSSK4N"},"outputs":[],"source":["import pandas as pd  #to load the dataframe\n","from sklearn.preprocessing import StandardScaler  #to standardize the features\n","from sklearn.decomposition import PCA  #to apply PCA\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","path_input=\"/content/drive/Shareddrives/Progetto/Colab Notebooks/QuadTreeDatasetCompression/QuadTreeDatasetCompression.csv\"\n","path_output_finale=\"/content/drive/Shareddrives/Progetto/Colab Notebooks/PCA/DataFrameWithPCA2.csv\"\n","\n","if __name__=='__main__':\n","    #caricamento dei dati\n","    df = pd.read_csv(path_input, low_memory=False)\n","\n","    #elimino le colonne che non servono in modo da avere un dataframe contenente solo i vettori sui quali effettuare l'analisi\n","    vettori=df.iloc[:,5:]#elimino le colonne di id, pitch, yaw e roll\n","\n","    etichette=df.iloc[:,1:5]#prendo la restante parte del dataframe\n","\n","    #sostiuisco i valori nan con 0\n","    vettori=vettori.fillna(0)\n","\n","    #Standardizzare le feature\n","    scalar = StandardScaler()\n","    scaled_data = pd.DataFrame(scalar.fit_transform(vettori))#scaling dei dati\n","    print(\"SCALED DATA\\n\", scaled_data)\n","\n","    #Applichiamo la PCA\n","    #eseguo PCA su 600 componenti\n","    pca = PCA(n_components=600)\n","    pca.fit(scaled_data)\n","    data_pca = pca.fit_transform(scaled_data)\n","    data_pca = pd.DataFrame(data_pca)\n","    print(\"RISULTATO PCA \\n\", data_pca)\n","\n","    #La varianza spiegata dice quanta informazione (varianza) pu√≤ essere attribuita a ciascuna delle componenti principali.\n","    varianza=pca.explained_variance_ratio_\n","    print(varianza)\n","\n","    #print(\"Varianza\\n\", varianza)\n","    print(\"Somma varianze: \", np.sum(varianza))\n","\n","    #concateno le etichette del dataframe con il dataframe risultante dalla pca\n","    finale=pd.merge(left=etichette, right=data_pca, left_index=True, right_index=True)\n","\n","    #salvo il dataframe totale nel path di destinazione\n","    finale.to_csv(path_output_finale)"]}]}