{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Analisi della regressione sulle codifiche frattali ridimensionate risultanti dalla PCA"],"metadata":{"id":"Q989P-kBqXVW"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37CwA-usp5Rh","executionInfo":{"status":"ok","timestamp":1654956266385,"user_tz":-120,"elapsed":39471,"user":{"displayName":"MARCO COSTANTE","userId":"15932919196425756725"}},"outputId":"b40698be-0f91-41fd-ce2a-b12f9a592a0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import BayesianRidge\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import Lasso\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","from sklearn import preprocessing\n","from sklearn import utils\n","\n","path_input=\"/content/drive/Shareddrives/Progetto/Colab Notebooks/PCA/DataFrameWithPCA2.csv\"\n","\n","def get_Linear_Prediction(dati,dipendente):\n","    X_train, X_test, y_train, y_test = train_test_split(dati, dipendente, test_size=0.3, random_state=0)\n","\n","    #fit regressione lineare multipla sul train set\n","    regressor = LinearRegression()\n","    regressor.fit(X_train, y_train)\n","\n","    #predizione del set di test\n","    y_pred = regressor.predict(X_test)\n","\n","    #calcoliamo l'errore assoluto medio\n","    errore = mean_absolute_error(y_test, y_pred)\n","    print(\"MAE:\", errore)\n","\n","    return y_pred, errore\n","\n","def get_Bayesan_Prediction(dati,dipendente):\n","    X_train, X_test, y_train, y_test = train_test_split(dati, dipendente, test_size=0.3, random_state=0)\n","\n","    #fit regressione lineare multipla sul train set\n","    regressor = BayesianRidge()\n","    regressor.fit(X_train, y_train)\n","\n","    #predizione del set di test\n","    y_pred = regressor.predict(X_test)\n","\n","    #calcoliamo l'errore assoluto medio\n","    errore = mean_absolute_error(y_test, y_pred)\n","\n","    print(\"MAE:\", errore)\n","\n","    return y_pred, errore\n","\n","def get_Lasso_Prediction(dati,dipendente):\n","    X_train, X_test, y_train, y_test = train_test_split(dati, dipendente, test_size=0.3, random_state=0)\n","\n","    #fit regressione lineare multipla sul train set\n","    regressor = Lasso(alpha=0.0001, max_iter=100000)\n","    regressor.fit(X_train, y_train)\n","\n","    #predizione del set di test\n","    y_pred = regressor.predict(X_test)\n","\n","    #calcoliamo l'errore assoluto medio\n","    errore = mean_absolute_error(y_test, y_pred)\n","    print(\"MAE:\", errore)\n","\n","    return y_pred, errore\n","\n","def get_GradientBoost_Prediction(dati,dipendente):\n","    X_train, X_test, y_train, y_test = train_test_split(dati, dipendente, test_size=0.3, random_state=0)\n","\n","    #fit regressione lineare multipla sul train set\n","    regressor = GradientBoostingRegressor()\n","    regressor.fit(X_train, y_train)\n","\n","    #predizione del set di test\n","    y_pred = regressor.predict(X_test)\n","\n","    #calcoliamo l'errore assoluto medio\n","    errore = mean_absolute_error(y_test, y_pred)\n","    print(\"MAE:\", errore)\n","\n","    return y_pred, errore\n","\n","def get_XGBoost_Prediction(dati,dipendente):\n","    X_train, X_test, y_train, y_test = train_test_split(dati, dipendente, test_size=0.3, random_state=0)\n","\n","    #fit regressione lineare multipla sul train set\n","    regressor = xgb.XGBRegressor()\n","    regressor.fit(X_train, y_train)\n","\n","    #predizione del set di test\n","    y_pred = regressor.predict(X_test)\n","\n","    #calcoliamo l'errore assoluto medio\n","    errore = mean_absolute_error(y_test, y_pred)\n","    print(\"MAE:\", errore)\n","\n","    return y_pred, errore\n","\n","if __name__=='__main__':\n","    #caricamento dei dati\n","    df = pd.read_csv(path_input, low_memory=False)\n","\n","    print(\"DATAFRAME TOTALE\\n\",df.head())\n","\n","    #elimino le colonne che non servono in modo da avere un dataframe contenente solo i vettorii\n","    vettori=df.iloc[:,5:]\n","\n","    etichette=df.iloc[:,1]#prendo gli id\n","    #print(\"etichette\\n\",etichette)\n","\n","    pitch=df.iloc[:,2]\n","    #print(\"PITCH\\n\",pitch)\n","    yaw=df.iloc[:,3]\n","    #print(\"YAW\\n\",yaw)\n","    roll=df.iloc[:,4]\n","    #print(\"ROLL\\n\",roll )\n","\n","    #**********************************************************************\n","    print(\"***************LINEAR REGRESSION********************\")\n","\n","    #regressione pitch\n","    print(\"Pitch error linear regression:\")\n","    predizioni, errore =get_Linear_Prediction(vettori, pitch)\n","\n","    #regressione yaw\n","    print(\"Yaw error linear regression:\")\n","    predizioni, errore = get_Linear_Prediction(vettori, yaw)\n","\n","    #regressione roll\n","    print(\"Roll error linear regression:\")\n","    predizioni, errore = get_Linear_Prediction(vettori, roll)\n","\n","    #**********************************************************************\n","    print(\"***************BAYESAN REGRESSION********************\")\n","\n","    # regressione pitch\n","    print(\"Pitch error bayesan regression:\")\n","    predizioni, errore= get_Bayesan_Prediction(vettori, pitch)\n","\n","    # regressione yaw\n","    print(\"Yaw error bayesan regression:\")\n","    predizioni, errore= get_Bayesan_Prediction(vettori, yaw)\n","   \n","    # regressione roll\n","    print(\"Roll error bayesan regression:\")\n","    predizioni, errore= get_Bayesan_Prediction(vettori, roll)\n","  \n","    # **********************************************************************\n","    print(\"***************LASSO REGRESSION********************\")\n","\n","    # regressione pitch\n","    print(\"Pitch error lasso regression:\")\n","    predizioni, errore = get_Lasso_Prediction(vettori, pitch)\n","\n","    # regressione yaw\n","    print(\"Yaw error lasso regression:\")\n","    predizioni, errore = get_Lasso_Prediction(vettori, yaw)\n","\n","    # regressione roll\n","    print(\"Roll error lasso regression:\")\n","    predizioni, errore = get_Lasso_Prediction(vettori, roll)\n","\n","    # **********************************************************************\n","    print(\"***************XGB REGRESSION********************\")\n","\n","    # regressione pitch\n","    print(\"Pitch error gradient xgb regression:\")\n","    predizioni, errore = get_XGBoost_Prediction(vettori, pitch)\n","\n","    # regressione yaw\n","    print(\"Yaw error gradient xgb regression:\")\n","    predizioni, errore = get_XGBoost_Prediction(vettori, yaw)\n","\n","    # regressione roll\n","    print(\"Roll error gradient xgb regression:\")\n","    predizioni, errore = get_XGBoost_Prediction(vettori, roll)\n","\n","    # **********************************************************************\n","    print(\"***************GRADIENT BOOST REGRESSION********************\")\n","\n","    # regressione pitch\n","    print(\"Pitch error gradient boost regression:\")\n","    predizioni, errore = get_GradientBoost_Prediction(vettori, pitch)\n","\n","    # regressione yaw\n","    print(\"Yaw error gradient boost regression:\")\n","    predizioni, errore = get_GradientBoost_Prediction(vettori, yaw)\n","\n","    # regressione roll\n","    print(\"Roll error gradient boost regression:\")\n","    predizioni, errore = get_GradientBoost_Prediction(vettori, roll)\n","\n","\n","\n"],"metadata":{"id":"jlT31_zbpRyi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654957232828,"user_tz":-120,"elapsed":849346,"user":{"displayName":"MARCO COSTANTE","userId":"15932919196425756725"}},"outputId":"5df34b9f-8c8b-4017-d86f-d3d1df90cbab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DATAFRAME TOTALE\n","    Unnamed: 0                                           0     1     2     3  \\\n","0           0  1frame_00003_+007.61+003.29-001.57.png.csv  7.61  3.29 -1.57   \n","1           1  1frame_00004_+007.65+003.89-001.93.png.csv  7.65  3.89 -1.93   \n","2           2  1frame_00005_+007.45+003.66-001.95.png.csv  7.45  3.66 -1.95   \n","3           3    1frame_00006_+007.46+003.8-001.9.png.csv  7.46  3.80 -1.90   \n","4           4  1frame_00007_+007.73+003.43-002.12.png.csv  7.73  3.43 -2.12   \n","\n","          4         5         6         7         8  ...       594       595  \\\n","0 -3.451256  0.156735 -0.901562 -1.337726  1.453592  ... -0.203141 -1.038908   \n","1 -2.588053  0.280114 -1.895558 -1.457275  1.888257  ... -0.153565 -0.535291   \n","2 -1.684210 -0.251577 -2.537946 -1.932587  1.866695  ...  0.439204 -0.279401   \n","3 -2.912093  0.630476 -1.475526 -1.688048  1.299890  ... -0.023276 -0.031874   \n","4 -1.535888  0.027594 -1.916930 -0.561952  0.085151  ... -0.334038  0.961206   \n","\n","        596       597       598       599       600       601       602  \\\n","0  1.189221  1.610531 -0.263828  0.599291 -1.340694  0.315159 -0.610786   \n","1  0.862356  0.661974 -0.019331  0.250533 -1.811023 -0.225883  0.216817   \n","2  0.099206  0.581517 -0.779611  0.410438 -0.482791  0.370849 -0.914953   \n","3  0.669512  1.045278  0.358758 -0.221934 -0.951172  0.168905 -1.048759   \n","4  0.973302 -0.334495 -0.846928 -1.366125  1.494260 -0.333427 -0.957498   \n","\n","        603  \n","0  1.380195  \n","1  1.368562  \n","2  0.930826  \n","3  0.582829  \n","4  0.411173  \n","\n","[5 rows x 605 columns]\n","***************LINEAR REGRESSION********************\n","Pitch error linear regression:\n","MAE: 16.408545092772226\n","Yaw error linear regression:\n","MAE: 16.497256052821342\n","Roll error linear regression:\n","MAE: 9.434987562356175\n","***************BAYESAN REGRESSION********************\n","Pitch error bayesan regression:\n","MAE: 16.184925905628855\n","Yaw error bayesan regression:\n","MAE: 16.299333197263305\n","Roll error bayesan regression:\n","MAE: 9.08931375371145\n","***************LASSO REGRESSION********************\n","Pitch error lasso regression:\n","MAE: 16.408254825958313\n","Yaw error lasso regression:\n","MAE: 16.49698844419069\n","Roll error lasso regression:\n","MAE: 9.434483051386218\n","***************XGB REGRESSION********************\n","Pitch error gradient xgb regression:\n","[14:06:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","MAE: 15.71338903515175\n","Yaw error gradient xgb regression:\n","[14:07:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","MAE: 15.801467179644893\n","Roll error gradient xgb regression:\n","[14:08:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","MAE: 8.785082186013689\n","***************GRADIENT BOOST REGRESSION********************\n","Pitch error gradient boost regression:\n","MAE: 15.765245751573278\n","Yaw error gradient boost regression:\n","MAE: 15.832347928684044\n","Roll error gradient boost regression:\n","MAE: 8.78814943709554\n"]}]}]}